{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T01:21:24.218863Z","iopub.status.busy":"2022-09-03T01:21:24.218199Z","iopub.status.idle":"2022-09-03T01:21:24.225259Z","shell.execute_reply":"2022-09-03T01:21:24.224237Z","shell.execute_reply.started":"2022-09-03T01:21:24.218821Z"},"trusted":true},"outputs":[],"source":["%cd ../input/dogs-vs-cats"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T01:42:07.359221Z","iopub.status.busy":"2022-09-03T01:42:07.358542Z","iopub.status.idle":"2022-09-03T01:42:08.352285Z","shell.execute_reply":"2022-09-03T01:42:08.351041Z","shell.execute_reply.started":"2022-09-03T01:42:07.359186Z"},"trusted":true},"outputs":[],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T01:27:02.027252Z","iopub.status.busy":"2022-09-03T01:27:02.026574Z","iopub.status.idle":"2022-09-03T01:27:02.033907Z","shell.execute_reply":"2022-09-03T01:27:02.032756Z","shell.execute_reply.started":"2022-09-03T01:27:02.027213Z"},"trusted":true},"outputs":[],"source":["%cd working"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T07:37:18.527169Z","iopub.status.busy":"2022-09-03T07:37:18.526640Z","iopub.status.idle":"2022-09-03T07:37:30.562671Z","shell.execute_reply":"2022-09-03T07:37:30.561667Z","shell.execute_reply.started":"2022-09-03T07:37:18.527135Z"},"trusted":true},"outputs":[],"source":["import zipfile\n","train_path = \"../input/dogs-vs-cats/test.zip\"\n","\n","files = \"Data\"\n","\n","with zipfile.ZipFile(train_path, 'r') as zipp:\n","    zipp.extractall(files)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T07:37:48.257780Z","iopub.status.busy":"2022-09-03T07:37:48.257139Z","iopub.status.idle":"2022-09-03T07:37:48.279066Z","shell.execute_reply":"2022-09-03T07:37:48.277992Z","shell.execute_reply.started":"2022-09-03T07:37:48.257746Z"},"trusted":true},"outputs":[],"source":["import os\n","path_folder = 'Data/train/'\n","for file_name in os.listdir(path_folder)[:5]:\n","    image_path = path_folder + file_name\n","    print(image_path)\n","# print(len(os.listdir(path_folder)))"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T07:37:51.060752Z","iopub.status.busy":"2022-09-03T07:37:51.060181Z","iopub.status.idle":"2022-09-03T07:37:51.067762Z","shell.execute_reply":"2022-09-03T07:37:51.066605Z","shell.execute_reply.started":"2022-09-03T07:37:51.060717Z"},"trusted":true},"outputs":[],"source":["# import libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from tqdm import tqdm\n","import cv2\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch.nn as nn\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","import torchvision"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T07:37:53.623591Z","iopub.status.busy":"2022-09-03T07:37:53.623013Z","iopub.status.idle":"2022-09-03T07:37:53.631052Z","shell.execute_reply":"2022-09-03T07:37:53.629873Z","shell.execute_reply.started":"2022-09-03T07:37:53.623557Z"},"trusted":true},"outputs":[],"source":["class DogCatDataset(Dataset):\n","    \"\"\"\n","    create dataset\n","    \"\"\"\n","\n","    def __init__(self, dataset_file, transform=None):\n","        self.dataset = pd.read_csv(dataset_file)\n","        self.transform = transform\n","    \n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","\n","    def __getitem__(self, index):\n","        image_path, label = self.dataset.iloc[index]\n","        image = cv2.imread(image_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        if self.transform:\n","            image = Image.fromarray(image)\n","            image = self.transform(image)\n","            image = np.array(image)\n","        return image, label"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T07:37:55.365904Z","iopub.status.busy":"2022-09-03T07:37:55.365387Z","iopub.status.idle":"2022-09-03T07:37:55.381349Z","shell.execute_reply":"2022-09-03T07:37:55.380442Z","shell.execute_reply.started":"2022-09-03T07:37:55.365859Z"},"trusted":true},"outputs":[],"source":["class DogCatDataLoader:\n","    \"\"\"\n","    load dataset --> return train and valid dataset\n","    \"\"\"\n","\n","    def __init__(self, dataset_file,\n","                       batch_size=8,\n","                       random_seed=42,\n","                       valid_size=0.2,\n","                       shuffle=True):\n","        self.dataset_file = dataset_file\n","        self.batch_size = batch_size\n","        self.random_seed = random_seed\n","        self.valid_size = valid_size\n","        self.shuffle = shuffle\n","    \n","\n","    def create_data(self):\n","        normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n","                                         std=[0.2023, 0.1994, 0.2010],)\n","        tranform = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n","            transforms.RandomAffine(degrees=40, translate=None, scale=(1, 2), shear=15, resample=False, fillcolor=0),\n","            transforms.ToTensor(),\n","            normalize\n","        ])\n","\n","        train_dataset = DogCatDataset(dataset_file=self.dataset_file, transform=tranform) \n","        valid_dataset = DogCatDataset(dataset_file=self.dataset_file, transform=tranform)\n","\n","        num_train = len(train_dataset)\n","        indices = list(range(num_train))\n","        split = int(np.floor(self.valid_size * num_train))\n","\n","        if self.shuffle:\n","            np.random.seed(self.random_seed)\n","            np.random.seed(indices)\n","\n","        train_idx, valid_idx = indices[split:], indices[:split]\n","        train_sampler = SubsetRandomSampler(train_idx)\n","        valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","        train_loader = DataLoader(\n","            dataset=train_dataset, batch_size=self.batch_size, sampler=train_sampler\n","        )\n","\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset, batch_size=self.batch_size, sampler=valid_sampler\n","        )\n","\n","        return (train_loader, valid_loader)\n","#         return train_loader"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T07:39:43.333059Z","iopub.status.busy":"2022-09-03T07:39:43.332676Z","iopub.status.idle":"2022-09-03T07:39:43.353421Z","shell.execute_reply":"2022-09-03T07:39:43.352252Z","shell.execute_reply.started":"2022-09-03T07:39:43.333028Z"},"trusted":true},"outputs":[],"source":["class VGG16(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super(VGG16, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU())\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(), \n","            nn.MaxPool2d(kernel_size = 2, stride = 2))\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU())\n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2))\n","        self.layer5 = nn.Sequential(\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU())\n","        self.layer6 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU())\n","        self.layer7 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2))\n","        self.layer8 = nn.Sequential(\n","            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU())\n","        self.layer9 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU())\n","        self.layer10 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2))\n","        self.layer11 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU())\n","        self.layer12 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU())\n","        self.layer13 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2))\n","        self.fc = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(7*7*512, 4096),\n","            nn.ReLU())\n","        self.fc1 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU())\n","        self.fc2= nn.Sequential(\n","            nn.Linear(4096, num_classes),\n","            nn.Softmax(dim=1))\n","    \n","        \n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = self.layer5(out)\n","        out = self.layer6(out)\n","        out = self.layer7(out)\n","        out = self.layer8(out)\n","        out = self.layer9(out)\n","        out = self.layer10(out)\n","        out = self.layer11(out)\n","        out = self.layer12(out)\n","        out = self.layer13(out)\n","        out = out.reshape(out.size(0), -1)\n","        out = self.fc(out)\n","        out = self.fc1(out)\n","        out = self.fc2(out)\n","        return out"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T07:37:58.517538Z","iopub.status.busy":"2022-09-03T07:37:58.516910Z","iopub.status.idle":"2022-09-03T07:37:58.578607Z","shell.execute_reply":"2022-09-03T07:37:58.577103Z","shell.execute_reply.started":"2022-09-03T07:37:58.517504Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T08:36:13.371671Z","iopub.status.busy":"2022-09-03T08:36:13.371111Z","iopub.status.idle":"2022-09-03T08:46:49.991932Z","shell.execute_reply":"2022-09-03T08:46:49.989668Z","shell.execute_reply.started":"2022-09-03T08:36:13.371636Z"},"trusted":true},"outputs":[],"source":["dataset_folder = \"Data/train/\"\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","num_classes = 2\n","num_epochs = 10\n","batch_size = 16\n","learning_rate = 0.005\n","weight_decay = 0.005\n","\n","# model = VGG16(num_classes).to(device)\n","\n","model = torchvision.models.vgg16(pretrained=True)\n","model.classifier[-1] = nn.Linear(in_features=4096, out_features=2)\n","model = model.to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# dataset loader\n","dataset_file = \"../input/cat-dog-recognition/train.csv\"\n","data_loader = DogCatDataLoader(dataset_file=dataset_file, batch_size=batch_size)\n","train_loader, valid_loader = data_loader.create_data()\n","# train_loader = data_loader.create_data()\n","\n","# Train the model\n","iterations = len(train_loader)\n","\n","print(\"Start training...\")\n","loss_opt = 1e9\n","for epoch in range(num_epochs):\n","    loss = None\n","    for i, (images, labels) in tqdm(enumerate(train_loader)):\n","        # Move tensors to the configured device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","      \n","    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, i+1, iterations, loss.item()))\n","    if loss < loss_opt:\n","        loss_opt = loss\n","        torch.save(model.state_dict(), 'best.pth')\n","            \n","    # Validation\n","    with torch.no_grad(): \n","        # turn off model.train() -> turn on model.eval() -> turn off model.eval() -> and then auto turn on model.train() again\n","        correct = 0\n","        total = 0\n","        for images, labels in valid_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            outputs = F.softmax(outputs, dim=1)\n","#             print(outputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","#             print(predicted)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            del images, labels, outputs\n","        print('Accuracy of the network on the validation images: {} %'.format(100 * correct / total)) "]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T09:26:00.356503Z","iopub.status.busy":"2022-09-03T09:26:00.355831Z","iopub.status.idle":"2022-09-03T09:26:04.177419Z","shell.execute_reply":"2022-09-03T09:26:04.176399Z","shell.execute_reply.started":"2022-09-03T09:26:00.356469Z"},"trusted":true},"outputs":[],"source":["check_point = './best.pth'\n","model_test = torchvision.models.vgg16()\n","model_test.classifier[-1] = nn.Linear(in_features=4096, out_features=2)\n","model_test.load_state_dict(torch.load(check_point))\n","model_test = model_test.to(device)\n","print(model_test)"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2022-09-03T09:26:07.689149Z","iopub.status.busy":"2022-09-03T09:26:07.688091Z","iopub.status.idle":"2022-09-03T09:26:07.714010Z","shell.execute_reply":"2022-09-03T09:26:07.713031Z","shell.execute_reply.started":"2022-09-03T09:26:07.689101Z"},"trusted":true},"outputs":[],"source":["image_path = './Data/test1/225.jpg'\n","image = cv2.imread(image_path)\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n","                                         std=[0.2023, 0.1994, 0.2010],)\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    normalize\n","])\n","\n","image = Image.fromarray(image)\n","image = transform(image)\n","# print(image.shape)\n","image = image.unsqueeze(0)\n","image = image.to(device)\n","\n","model_test.eval()\n","output = model_test(image)\n","output = F.softmax(output, dim=1)\n","value_hat, label_hat = torch.max(output.data, 1)\n","print(label_hat)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('env39')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"a1dacac554b42be00a58a286c23b773f2ace0398abe72c3c8ef0a6bc184a28bf"}}},"nbformat":4,"nbformat_minor":4}
